import json
import re

from transformers import AutoModelForCausalLM, AutoTokenizer
import plac
from tqdm import tqdm

from retrievers.ICLRetrieverBM25 import ICLRetrieverBM25Monolingual, ICLRetrieverBM25Translated
from retrievers.ICLRetrieverRandom import ICLRetrieverRandom
from retrievers.ICLRetrieverEmbeddings import ICLRetrieverEmbeddings
from retrievers.ICLRetrieverTranslationEmbeddings import ICLRetrieverTranslationEmbeddings


def construct_prompt(text, exemplars):
    prompt = "Respond 0 or 1 to determine whether the following paragraph was generated by a human or computer. Respond 0 if it is human-generated or 1 if it is computer-generated. Only respond with either the number 0 or 1."
    if exemplars:
        prompt += "\nFor Example,\n"
    for exemplar, label in exemplars:
        prompt += f"Paragraph: {exemplar}\nResponse: {label}\n"
    prompt += f"Paragraph: {text}\nResponse: "
    return prompt

def extract_label(text):
    response = re.findall("Response: (.*)$", text, flags=re.MULTILINE)
    if response:
        return response[-1]
    else:
        return -1

def main(retriever_name: str, test_file: str, output_file: str, k: int, in_language: bool):
    in_language = False
    checkpoint = "bigscience/bloomz-3b"
    tokenizer = AutoTokenizer.from_pretrained(checkpoint)
    model = AutoModelForCausalLM.from_pretrained(checkpoint, torch_dtype="auto", device_map="auto")
    print("Model and Tokenizer Loaded")

    retriever_dict = {"BM25Monolingual"       : ICLRetrieverBM25Monolingual,
                      "BM25Translated"        : ICLRetrieverBM25Translated,
                      "Random"                : ICLRetrieverRandom,
                      "Embeddings"            : ICLRetrieverEmbeddings,
                      "TranslationEmbeddings" : ICLRetrieverTranslationEmbeddings}
    
    if in_language:
        langs = ['arabic', 'russian', 'chinese', 'indonesian', 'urdu', 'bulgarian', 'german', 'english']
        retrievers = {}
        for language in langs:
            train_file = f"data/SubtaskA/subtaskA_train_multilingual_{language}.jsonl"
            with open(train_file, 'r') as f:
                train_data = [json.loads(line) for line in f]
            retrievers[language] = retriever_dict[retriever_name](train_data)
    else:  # cross-lingual
        train_file = "data/SubtaskA/subtaskA_train_multilingual_processed_combined.jsonl"
        with open(train_file, 'r') as f:
            train_data = [json.loads(line) for line in f]
        retriever = retriever_dict[retriever_name](train_data)

    with open(test_file, 'r') as f_in, open(output_file, 'w') as f_out:
        for line in tqdm(f_in):
            datum = json.loads(line)
            text = datum['text']

            if in_language:
                if datum['source'] in retrievers:
                    retriever = retrievers[datum['source']]
                else:
                    retriever = retrievers['english']

            # exemplars = retriever(text, int(k))
            exemplars = []

            inputs = tokenizer.encode(construct_prompt(text, exemplars), return_tensors="pt").to("cuda")
            outputs = model.generate(inputs, max_length = 4000)
            response = tokenizer.decode(outputs[0])

            label = extract_label(response)
            f_out.write(json.dumps({"id": datum['id'], "label": label}) + "\n")

if __name__ == "__main__":
    plac.call(main)